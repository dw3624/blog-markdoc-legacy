---
title: tf-idf 알아보기
tags: nlp
mathjax: true
---

$$tf-idf$$는 자연어처리에 사용되는 원리며, elastic search 등에 주로 사용된다.  
수식은 아래와 같다.

$$\text{ tf-idf(t,d) } = tf(t, d) * idf(t) = { {\#~of~t~ind} \over {\#d} } * log { { \#D} \over {\# \{ d \in D | t \in d \}} }$$


## 1. 배경
$$\text{ tf-idf }$$는 term frequency - inverse document frequency의 약자다.  
문장의 분석에 주로 사용되며, 자연어처리(NLP)나 추천, 검색 등에 이용된다. 이번 포스트에서는 주로 검색에서 쓰이는 원리를 알아보도록 한다.


"비둘기의 부리"를 검색한다고 가정했을때, 아래의 두 가지를 고려해 결과를 보여줘야 한다.  
 1. 검색결과로 어떤 것을 보여줄지
 2. 어떤 순서로 배열할지


단순히 생각한다면 아래와 같은 해법을 생각할 수 있다.  
 1. "비둘기", "의", "부리" 중 하나라도 포함한다면 검색결과로 표시
 2. 등장횟수 합계 많은 순으로 배열


그러나 단순한 해법은 다음과 같은 문제를 야기할 수 있다.  
 1. "의"의 등장횟수가 많아 관련없는 결과도 표시
 2. 긴 문장이 무조건적으로 유리  

**$$tf-idf$$는 위 문제를 해결할 수 있다...!!**




## 2. 정의 & 의미
$$tf-idf(t, d)$$는  **희귀한 단어**가 **자주 등장할 수록** 높은 점수를 부여해, 단어와 문장이 일치하는 정도를 측정한다.  
 - 높은 등장빈도 : 높은 점수
 - 희귀 단어       : 높은 점수




### 가정 설정
 1. 대량의 문장데이터가 존재
   - 문장의 집합을 $$D$$로 표기
      - $$D$$ = {문장1, 문장2, ...}
      - $$\#D$$ : 문장 개수
 2. 문장 속에 단어가 존재
   - 문장 $$d(\in D)$$는 $$d = (t_1, t_2, ..., t_N)$$
   - $$N = \#d$$ : 단어 개수
 3. 단어 $$t$$가 문장 $$d$$ 속에 나타남 ($$t \in d$$)




### 정의

$$tf(t,d) = { {단어~t의~등장~횟수} \over {문장~d의~단어수} } = { {\#~of~t~ind} \over {\#d} }$$

$$idf(t) = { log { {모든~문장수} \over {단어~t를~포함한~문장수} } }= {log { {\#D} \over {\# \{ d \in D | t \in d \} }}}$$

$$\text{ tf-idf(t,d) } = tf(t,d) * idf(t)$$




### 의미
#### $$tf$$의 의미
 - 문장 $$d$$에서의 단어 $$t$$ 비율
 - 절대수가 등장 비율을 사용해, 긴 문장이 유리하다는 문제를 해결

#### $$idf$$의 의미

$${ { \# \{ d \in D | t \in d \} } \over { \# D } } = p(t)$$

 - 전체 문장 대비 단어 $$t$$를 포함하는 문장의 비율
 - 무작위로 문장을 추출했을때 단어 $$t$$를 포함하는 확률 $$p(t)$$, 희귀도


$${ { \# D } \over { \# \{ d \in D | t \in d \} }  }= { {1} \over { p(t) } }$$

 - 단어 $$t$$의 희귀도
 - 값이 크면 클수록 희귀


#### 예시
"비둘기의 부리"의 경우, $${ {1} \over {p(부리)} } \gt { {1} \over {p(비둘기)} } \gt { {1} \over {p(의)} }$$에서  
$$tf(부리) * { {1} \over {p(부리)} } + tf(비둘기) * { {1} \over {p(비둘기)} } + tf(의) * { {1} \over {p(의)} }$$로 순위를 매기면,  
 - "부리"를 많이 포함하면 상위 검색결과로
 - "비둘기"를 포함하면 가산점
 - "의"를 포함하면 약간 가산점  
**바람직한 검색순위를 기대할 수 있다...!!**

<br />
<br />

#### $$log$$를 사용하는 이유
 - $$log * { {1} \over {p(t)} }$$ 는 정보량을 표현
 - 예를 들어 복권 당첨번혼를 알려준다고 할 때, 
 1. 아래 한 자리는 6 : $${log {1} \over {(1/10)} } = log10 \doteqdot 2.3$$
 2. 아래 여섯 자리는 123456 : $${log {1} \over { (1/10)^6 } } = 6log10 \doteqdot 14.8$$
   - 2가 1보다 정보량이 더 많으며, 이를 수식화 한 것이 $$log$$를 이용한 위 식이며, 정보량이 얼마나 차이나는지를 계산할 수 있도록 해준다.
 - 따라서 희귀도 $${1} \over {p(t)}$$가 아닌 정보량 $$log{ {1} \over {p(t)} }$$ (= $$idf$$)를 사용한다.


---


## 3. 정리

$$\text{ tf-idf(t,d) } = tf(t,d) * idf(t) = \text{(t의 비율)} * \text{(단어t의 등장에 대한 정보량)} $$

$$tf-idf$$는 단어의 등장빈도($$tf$$)와 정보이론의 관점($$idf$$)으로 단어 $$t$$와 문장 $$d$$의 매치율을 계산하는 기법이다.

---